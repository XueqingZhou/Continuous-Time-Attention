<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, customized for Continuous-Time Attention -->
  <meta name="description" content="Project page for &quot;Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers&quot;, EMNLP 2025.">
  <meta property="og:title" content="Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers"/>
  <meta property="og:description" content="Project page for EMNLP 2025 paper on PDE-guided continuous-time attention mechanisms for long-sequence Transformers."/>
  <meta property="og:url" content="https://github.com/XueqingZhou/XueqingZhou-Continuous-Time-Attention"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="assets/images/teaser.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers">
  <meta name="twitter:description" content="EMNLP 2025 project page for PDE-guided continuous-time attention mechanisms for long-sequence Transformers.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="assets/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="continuous-time attention, PDE, long-sequence Transformers, EMNLP 2025, deep learning, natural language processing">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Continuous-Time Attention</title>
  <link rel="icon" type="image/x-icon" href="assets/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="assets/css/bulma.min.css">
  <link rel="stylesheet" href="assets/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="assets/css/bulma-slider.min.css">
  <link rel="stylesheet" href="assets/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="assets/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="assets/js/fontawesome.all.min.js"></script>
  <script src="assets/js/bulma-carousel.min.js"></script>
  <script src="assets/js/bulma-slider.min.js"></script>
  <script src="assets/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <span>Yukun Zhang</span><sup>*</sup>,</span>
              <span class="author-block">
                <span>Xueqing Zhou</span><sup>*</sup>
              </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">The Chinese University of Hong Kong &nbsp;&nbsp;&nbsp; Fudan University<br><b>EMNLP 2025</b></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- OpenReview PDF link -->
                      <span class="link-block">
                        <a href="https://aclanthology.org/2025.emnlp-main.1097.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                        </a>
                      </span>

                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/XueqingZhou/XueqingZhou-Continuous-Time-Attention" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code (Coming Soon)</span>
                        </a>
                      </span>

                      <!-- ArXiv Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2505.20666" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                        </a>
                      </span>

                  </div>
              </div>
            </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/images/teaser.png" alt="Teaser"/>
      <h2 class="subtitle has-text-centered">
        Continuous-Time Attention models token interactions as solutions of partial differential equations (PDEs) in continuous time,
        enabling efficient and stable modeling of long-range dependencies in Transformers.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <b>TL;DR:</b> We introduce Continuous-Time Attention, a PDE-guided attention mechanism that treats self-attention as a continuous-time
    dynamical system, improving long-sequence modeling efficiency and stability for Transformers.
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Transformers achieve state-of-the-art performance on a wide range of sequence modeling tasks, but their quadratic attention
            complexity and discrete-layer parameterization make long-sequence modeling both expensive and difficult to analyze.
            We propose <b>Continuous-Time Attention</b>, a PDE-guided formulation of self-attention that treats token interactions as trajectories
            of a continuous-time dynamical system governed by partial differential equations.
            This view allows us to derive new attention mechanisms with better control over information propagation, improved stability for
            long-range dependencies, and favorable computational properties for long sequences.
            We instantiate our framework in several long-sequence benchmarks, where Continuous-Time Attention attains competitive or superior
            performance to strong Transformer baselines while offering a principled lens on how information flows across depth and positions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
        </div>
      </div>
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="assets/images/homonym_explain.png" alt="Homonyms Explanation"/>
        <h2 class="subtitle has-text-centered">
          Homonyms. We see that the word "baseball" provides the required synergistic context with the homonym "bat" to pick the 
          sports setting over the animal. This effect can be confirmed in the synergy maps and image-level synergy values (S) as 
          well where we observe a high synergy for "bat" with "baseball" compared to other words such as "He" and "swung".
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/images/homonym_result.png" alt="Homonyms Result"/>
        <h2 class="subtitle has-text-centered">
          Homonyms. Left: Successful generation of homonym "bowl" in different contexts due to high synergy with modifiers "bowl" 
          and "game". Right: Failure case where the model generates the homonym "mole" with the same semantic meaning, the animal, 
          due to its failure to use contextual information from words like "coworker" as can be seen in the synergy map.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/images/synonym_result.png" alt="Synonyms Results"/>
        <h2 class="subtitle has-text-centered">
          Synonyms. Our redundancy map is able to highlight that the model considers the pairs "bed" and "mattress" (left) and "cube" 
          and "cuboid" (right) as semantically similar
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="assets/images/hypo_result_coco.png" alt="Co-Hyponyms Results"/>
      <h2 class="subtitle has-text-centered">
        COCO Co-Hyponyms. The redundancy map proves to be very useful in finding out the reason behind the model’s failures in these figures. 
        It confuses the co-hyponym pairs ("sandwich", "pizza")(left) and ("elephant", "cat")(right) to have the same meaning for the co-hyponyms 
        as seen from the redundancy maps, which results in erroneous generations
      </h2>
    </div>
     <div class="item">
      <!-- Your image here -->
      <img src="assets/images/p_intervention_r1.png" alt="Prompt Intervention Results"/>
      <h2 class="subtitle has-text-centered">
        Prompt Intervention. The redundancy is highly activated in the face region of the giraffe. On a closer look, we see that the face is that 
        of a cow meaning that the word "cow" is redundant. This is confirmed as the image changes very little on omitting it from the prompt.
      </h2>
    </div>
     <div class="item">
      <!-- Your image here -->
      <img src="assets/images/uniqueness_mrf_new.png" alt="Uniqueness Results"/>
      <h2 class="subtitle has-text-centered">
        Most Representative Features. Left: The "toothbrush" uniqueness map correctly captures the toothbrush bristles, their most distinct feature. 
        Right: The "bear" uniqueness map correctly captures the bear region, specifically the face.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->






<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@inproceedings{zhang-zhou-2025-continuous,
  title = {Continuous-Time Attention: {PDE}-Guided Mechanisms for Long-Sequence Transformers},
  author = {Zhang, Yukun and
    Zhou, Xueqing},
  editor = {Christodoulopoulos, Christos and
    Chakraborty, Tanmoy and
    Rose, Carolyn and
    Peng, Violet},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  month = nov,
  year = {2025},
  address = {Suzhou, China},
  publisher = {Association for Computational Linguistics},
  url = {https://aclanthology.org/2025.emnlp-main.1097/},
  doi = {10.18653/v1/2025.emnlp-main.1097},
  pages = {21654--21674},
  ISBN = {979-8-89176-332-6},
  abstract = {We present Continuous-Time Attention, a novel framework that infuses partial differential equations (PDEs) into the Transformer's attention mechanism to better handle long sequences. Instead of relying on a static attention matrix, we allow attention weights to evolve along a pseudo-time dimension governed by diffusion, wave, or reaction-diffusion dynamics. This dynamic process systematically smooths local noise, strengthens long-range dependencies, and improves gradient stability during training. Our theoretical analysis shows that PDE-driven attention mitigates the exponential decay of distant interactions and improves the optimization landscape. Empirically, Continuous-Time Attention achieves consistent performance gains over both standard and long-sequence Transformer variants across a range of tasks. These results suggest that embedding continuous-time dynamics into attention mechanisms is a promising direction for enhancing global coherence and scalability in Transformer models. Code is publicly available at: https://github.com/XueqingZhou/XueqingZhou-Continuous-Time-Attention}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This template was borrowed from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> 
            project page under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
